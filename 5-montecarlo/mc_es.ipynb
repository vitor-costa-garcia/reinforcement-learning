{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c6b8ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monte Carlo ES\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "from blackjack_env import BlackJackEnv, CARD_INDX\n",
    "CARDS = [\"Ace\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\", \"Nine\", \"Ten\", \"Queen\", \"Jack\", \"King\"]\n",
    "CARDS_L = [\"Ace\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\", \"Nine\", \"Ten\"]\n",
    "N_ACTIONS = 2\n",
    "\n",
    "def mc_es(gamma, runs = 10000):\n",
    "    policy = np.random.randint(0, 2, size=(10,10,2,2))\n",
    "\n",
    "    for player_sum in range(10):\n",
    "        for dealer_card in range(10):\n",
    "            for usable_ace in range(2):\n",
    "                policy[player_sum][dealer_card][usable_ace][0] = 1\n",
    "\n",
    "    action_val = np.zeros(shape=(10,10,2,2))\n",
    "    returns = [[[[[] for _ in range(2)] for _ in range(2)] for _ in range(10)] for _ in range(10)]\n",
    "\n",
    "    bj = BlackJackEnv()    \n",
    "\n",
    "    for _ in range(runs):\n",
    "        episode = bj.run_episode(policy) #Returns a list of tuples (state, action, reward)\n",
    "        g = 0\n",
    "        seen_states = []\n",
    "        for i in reversed(range(len(episode))):\n",
    "            g = g * gamma + episode[i][2]\n",
    "            state_action_pair = (episode[i][0], episode[i][1])\n",
    "\n",
    "            act = episode[i][1]\n",
    "            aces = episode[i][0]['usable_aces']\n",
    "            dealer = CARD_INDX[episode[i][0]['dealer_card']]\n",
    "            player = episode[i][0]['hand_sum'] - 12\n",
    "\n",
    "            if state_action_pair not in seen_states:\n",
    "                seen_states.append(state_action_pair)\n",
    "                returns[player][dealer][aces][act].append(g)\n",
    "                action_val[player][dealer][aces][act] = np.mean(returns[player][dealer][aces][act])\n",
    "\n",
    "                q_values_for_state = [action_val[player][dealer][aces][0], action_val[player][dealer][aces][1]]\n",
    "                opt_action = np.argmax(q_values_for_state)\n",
    "\n",
    "                for possible_action in range(N_ACTIONS):\n",
    "                    policy[player][dealer][aces][possible_action] = 0\n",
    "                    if possible_action == opt_action:\n",
    "                        policy[player][dealer][aces][possible_action] = 1\n",
    "                    #         |--------State-------||-----Action----|\n",
    "\n",
    "    return action_val, policy\n",
    "\n",
    "def mc_w_es(epsilon, gamma, runs = 10000):\n",
    "    policy = np.zeros(shape=(10,10,2,2))\n",
    "    for player_sum in range(10):\n",
    "        for dealer_card in range(10):\n",
    "            for usable_ace in range(2):\n",
    "                policy[player_sum][dealer_card][usable_ace][0] = 1\n",
    "    action_val = np.zeros(shape=(10,10,2,2))\n",
    "    returns = [[[[[] for _ in range(2)] for _ in range(2)] for _ in range(10)] for _ in range(10)]\n",
    "\n",
    "    bj = BlackJackEnv()    \n",
    "\n",
    "    for _ in range(runs):\n",
    "        episode = bj.run_episode(policy) #Returns a list of tuples (state, action, reward)\n",
    "        g = 0\n",
    "        seen_states = []\n",
    "        for i in reversed(range(len(episode))):\n",
    "            g = g * gamma + episode[i][2]\n",
    "            state_action_pair = (episode[i][0], episode[i][1])\n",
    "\n",
    "            act = episode[i][1]\n",
    "            aces = episode[i][0]['usable_aces']\n",
    "            dealer = CARD_INDX[episode[i][0]['dealer_card']]\n",
    "            player = episode[i][0]['hand_sum'] - 12\n",
    "\n",
    "            if state_action_pair not in seen_states:\n",
    "                seen_states.append(state_action_pair)\n",
    "                returns[player][dealer][aces][act].append(g)\n",
    "                action_val[player][dealer][aces][act] = np.mean(returns[player][dealer][aces][act])\n",
    "\n",
    "                q_values_for_state = [action_val[player][dealer][aces][0], action_val[player][dealer][aces][1]]\n",
    "                opt_action = np.argmax(q_values_for_state)\n",
    "                for possible_action in range(N_ACTIONS):\n",
    "                    policy[player][dealer][aces][possible_action] = epsilon/N_ACTIONS\n",
    "                    if possible_action == opt_action:\n",
    "                        policy[player][dealer][aces][possible_action] = 1 - epsilon + (epsilon/N_ACTIONS)\n",
    "\n",
    "    return action_val, policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1acb39ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_val, policy = mc_w_es(0.05, 1, 500000) #500k runs 5m 29s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68f63d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#action_val, policy = mc_es(1, 500000) #500k runs 5m 29s\n",
    "\n",
    "policy_dealer = np.zeros(shape=(10,10,2,2))\n",
    "\n",
    "for player_sum_idx in range(10): # simulating dealers policy\n",
    "    actual_player_sum = player_sum_idx + 12\n",
    "    for dealer_card_idx in range(10):\n",
    "        for usable_ace_idx in range(2):\n",
    "            if actual_player_sum >= 17:\n",
    "                policy_dealer[player_sum_idx][dealer_card_idx][usable_ace_idx][0] = 0 # Hit\n",
    "                policy_dealer[player_sum_idx][dealer_card_idx][usable_ace_idx][1] = 1 # Stick\n",
    "            else:\n",
    "                policy_dealer[player_sum_idx][dealer_card_idx][usable_ace_idx][0] = 1 \n",
    "                policy_dealer[player_sum_idx][dealer_card_idx][usable_ace_idx][1] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed3471cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.216035\n",
      "-0.222035\n"
     ]
    }
   ],
   "source": [
    "bjtable = BlackJackEnv()\n",
    "n = 300000\n",
    "\n",
    "for pol in [policy, policy_dealer]:\n",
    "    w = 0\n",
    "    d = 0\n",
    "    l = 0\n",
    "    for _ in range(n):\n",
    "        episode = bjtable.run_episode(pol)\n",
    "        match episode[-1][2]:\n",
    "            case 1:\n",
    "                w += 1\n",
    "            case 1.5:\n",
    "                w += 1.5\n",
    "            case 0:\n",
    "                d += 1\n",
    "            case -1:\n",
    "                l += 1\n",
    "\n",
    "    print((w-l)/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5280b9ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m n_usable_ace = [[pol_used[i][j][\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10\u001b[39m)] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10\u001b[39m)]\n\u001b[32m      8\u001b[39m usable_ace = [[pol_used[i][j][\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10\u001b[39m)] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10\u001b[39m)]\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m state_values_noace = np.array([[\u001b[43maction_val\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpol_used\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10\u001b[39m)] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10\u001b[39m)])\n\u001b[32m     10\u001b[39m state_values_ace = np.array([[action_val[i][j][\u001b[32m1\u001b[39m][pol_used[i][j][\u001b[32m1\u001b[39m]] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10\u001b[39m)] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10\u001b[39m)])\n\u001b[32m     12\u001b[39m fig1, ax1 = plt.subplots(\u001b[32m1\u001b[39m,\u001b[32m2\u001b[39m, figsize=(\u001b[32m10\u001b[39m,\u001b[32m8\u001b[39m))\n",
      "\u001b[31mIndexError\u001b[39m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('_mpl-gallery-nogrid')\n",
    "\n",
    "for pol_used in [policy]:\n",
    "\n",
    "    n_usable_ace = [[pol_used[i][j][0] for j in range(10)] for i in range(10)]\n",
    "    usable_ace = [[pol_used[i][j][1] for j in range(10)] for i in range(10)]\n",
    "    state_values_noace = np.array([[action_val[i][j][0][pol_used[i][j][0]] for j in range(10)] for i in range(10)])\n",
    "    state_values_ace = np.array([[action_val[i][j][1][pol_used[i][j][1]] for j in range(10)] for i in range(10)])\n",
    "\n",
    "    fig1, ax1 = plt.subplots(1,2, figsize=(10,8))\n",
    "\n",
    "    ax1[0].imshow(n_usable_ace, origin='lower')\n",
    "    ax1[0].set_title(\"No usable aces policy\")\n",
    "    ax1[0].set_xticks(np.arange(0,10))\n",
    "    ax1[0].set_yticks(np.arange(0,10))\n",
    "    ax1[0].set_xticklabels(CARDS_L)\n",
    "    ax1[0].set_yticklabels(np.arange(12,22))\n",
    "    ax1[0].set_ylabel(\"Dealer's card\")\n",
    "    ax1[0].set_ylabel(\"Player's hand sum\")\n",
    "\n",
    "    ax1[1].imshow(usable_ace, origin='lower')\n",
    "    ax1[1].set_title(\"Usable aces policy\")\n",
    "    ax1[1].set_xticks(np.arange(0,10))\n",
    "    ax1[1].set_yticks(np.arange(0,10))\n",
    "    ax1[1].set_xticklabels(CARDS_L)\n",
    "    ax1[1].set_yticklabels(np.arange(12,22))\n",
    "    ax1[1].set_xlabel(\"Dealer's card\")\n",
    "    ax1[1].set_ylabel(\"Player's hand sum\")\n",
    "    ax1[1].legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    player_sum = np.arange(12, 22)\n",
    "    dealer_card = np.arange(1, 11)\n",
    "    X, Y = np.meshgrid(dealer_card, player_sum)\n",
    "\n",
    "    fig2 = plt.figure(figsize=(11,9))\n",
    "    ax2_0 = fig2.add_subplot(1,2,1,projection='3d')\n",
    "    ax2_1 = fig2.add_subplot(1,2,2,projection='3d')\n",
    "\n",
    "    ax2_0.plot_surface(X,Y,state_values_noace, cmap='coolwarm')\n",
    "    ax2_0.set_title(\"No usable aces value function\")\n",
    "    ax2_0.set_xticks(np.arange(1, 11))\n",
    "    ax2_0.set_xticklabels(CARDS_L)\n",
    "    ax2_0.set_xlabel(\"Dealer's card\")\n",
    "    ax2_0.set_yticks(np.arange(12,22))\n",
    "    ax2_0.set_yticklabels(np.arange(12,22))\n",
    "    ax2_0.set_ylabel(\"Player's hand sum\")\n",
    "    ax2_0.set_zlabel(\"Value function\")\n",
    "    \n",
    "    ax2_1.plot_surface(X,Y,state_values_ace, cmap='coolwarm')\n",
    "    ax2_1.set_title(\"Usable aces value function\")\n",
    "    ax2_1.set_xticks(np.arange(1, 11))\n",
    "    ax2_1.set_xticklabels(CARDS_L)\n",
    "    ax2_1.set_xlabel(\"Dealer's card\")\n",
    "    ax2_1.set_yticks(np.arange(12,22))\n",
    "    ax2_1.set_yticklabels(np.arange(12,22))\n",
    "    ax2_1.set_ylabel(\"Player's hand sum\")\n",
    "    ax2_1.set_zlabel(\"Value function\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747af079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
